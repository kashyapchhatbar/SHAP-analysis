## Unravelling epigenetic regulation of gene expression with explainable AI - a case study leveraging degron data

Transcriptional regulation involves complex interactions involving chromatin-associated proteins, but disentangling these mechanistically remains challenging. Here, we generate deep learning models to predict RNA Pol-II occupancy from chromatin-associated protein profiles in unperturbed conditions. We evaluate the suitability of Shapley Additive Explanations (SHAP), a widely used explainable AI (XAI) approach, to infer causality and analyse regulatory mechanisms across diverse datasets and to validate these insights using data from degron-based perturbation experiments. Remarkably, genes ranked by SHAP importance predict direct targets of perturbation even from unperturbed data, enabling inference without costly experimental interventions. Our analysis reveals that SHAP not only predicts differential gene expression but also captures the magnitude of transcriptional changes. We validate the cooperative roles of SET1A and ZC3H4 at promoters and distinct regulatory contributions of ZC3H4 at gene bodies in influencing transcription. Cross-dataset validation uncovers unexpected connections between ZC3H4, a component of the Restrictor complex, and INTS11, part of the Integrator complex, suggesting crosstalk mediated by H3K4me3 and the SET1/COMPASS complex in transcriptional regulation. These findings highlight the power of integrating predictive modelling and experimental validation to unravel complex context-dependent regulatory networks and generate novel biological hypotheses.

### Repository Structure

- `data/`: Contains all datasets required for analysis, including fold change tables generated from DESeq2 after degron perturbation.
- `models/`: Contains all Python scripts for model training and SHAP analysis.
- `Figures.ipynb`: An IPython notebook for generating all the figures presented in the manuscript.

### Prerequisites

Reguired python libraries can be installed by executing `pip install -r requirements.txt`

### Step-by-Step Guide

#### Train the Model

To train the model on a relevant dataset:

Locate the dataset in the `data/` folder. Run the following command in your terminal:

`python models/MLPRegressor.py data/{dataset} 12`

- Replace {dataset} with the name of your dataset.
- 12 indicates the number of processors to use. Adjust this based on your system's configuration.

#### Generate SHAP Importance Values

To compute SHAP importance values:

Ensure the fold change table after degron perturbation (generated by DESeq2) is present in the `data/{dataset}/` folder. Run the following command:

`python models/MLPRegressor_SHAP.py data/{dataset}/ data/{dataset}/{degron}.deseq2.tsv "description"`

- Replace {dataset} with the dataset name.
- Replace {degron} with the specific degron perturbation (e.g., INTS11).
- "description" is an optional string to annotate the output.

### Generate Figures

All figures from the manuscript can be reproduced using the provided IPython notebook `Figures.ipynb`


Feel free to reach out via the repository's issue tracker if you encounter any issues or have questions about the analysis.

Shield: [![CC BY 4.0][cc-by-shield]][cc-by]

This work is licensed under a
[Creative Commons Attribution 4.0 International License][cc-by].

[![CC BY 4.0][cc-by-image]][cc-by]

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg
